#!/usr/bin/env python3
"""
ç¿»è¯‘å­—å¹• - ä½¿ç”¨ Groq LLM API
ä¸¤é˜¶æ®µç¿»è¯‘æ³•ï¼š
  Phase 1: å…¨æ–‡ç†è§£ç¿»è¯‘ - å°†å®Œæ•´å†…å®¹ä½œä¸ºä¸€ç¯‡æ–‡ç« ç¿»è¯‘
  Phase 2: æ—¶é—´ç åˆ†é… - æ ¹æ®æ¯æ®µæ—¶é•¿å‹ç¼©/æ‰©å……ç¿»è¯‘å†…å®¹
"""

import os
import sys
import json
import re
import time
from pathlib import Path
from typing import List, Dict, Optional

try:
    from groq import Groq
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£… groq: pip install groq")
    sys.exit(1)

from utils import seconds_to_time

# é»˜è®¤ç¿»è¯‘è¯è¡¨ï¼ˆä¸ SKILL.md ä¿æŒä¸€è‡´ï¼‰
DEFAULT_GLOSSARY = {
    "Trump": "å·æ™®",
    "Bessent": "è´æ£®ç‰¹",
}


def load_glossary(glossary_path: str = None) -> dict:
    """åŠ è½½ç¿»è¯‘è¯è¡¨"""
    glossary = DEFAULT_GLOSSARY.copy()
    if glossary_path and Path(glossary_path).exists():
        try:
            with open(glossary_path, 'r', encoding='utf-8') as f:
                external = json.load(f)
            if not isinstance(external, dict):
                raise ValueError("è¯è¡¨å¿…é¡»æ˜¯ JSON å¯¹è±¡ï¼ˆdictï¼‰")
            for k, v in external.items():
                if not isinstance(k, str) or not isinstance(v, str):
                    raise ValueError("è¯è¡¨çš„ key å’Œ value å¿…é¡»éƒ½æ˜¯å­—ç¬¦ä¸²")
            glossary.update(external)
            print(f"   ğŸ“– åŠ è½½å¤–éƒ¨è¯è¡¨: {len(external)} æ¡")
        except (json.JSONDecodeError, ValueError) as e:
            print(f"   âš ï¸  å¤–éƒ¨è¯è¡¨æ ¼å¼æ— æ•ˆï¼ˆ{e}ï¼‰ï¼Œä½¿ç”¨é»˜è®¤è¯è¡¨")
    return glossary


def build_glossary_prompt(glossary: dict) -> str:
    """æ„å»ºè¯è¡¨ prompt ç‰‡æ®µ"""
    if not glossary:
        return ""
    lines = ["\nç¿»è¯‘è¯è¡¨ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š"]
    for en, zh in glossary.items():
        lines.append(f"  {en} â†’ {zh}")
    return "\n".join(lines)


def call_llm(client: Groq, system_prompt: str, user_prompt: str,
             model: str = "llama-3.3-70b-versatile",
             temperature: float = 0.3, max_tokens: int = 8192,
             max_retries: int = 3) -> str:
    """è°ƒç”¨ Groq LLMï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    for retry in range(max_retries):
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=temperature,
                max_tokens=max_tokens,
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            if retry < max_retries - 1:
                wait = (retry + 1) * 2
                print(f"é‡è¯•({retry + 1})...", end=" ", flush=True)
                time.sleep(wait)
            else:
                raise
    return ""


def phase1_holistic_translate(
    client: Groq,
    subtitles: List[Dict],
    target_lang: str = "ä¸­æ–‡",
    source_lang: str = "è‹±æ–‡",
    model: str = "llama-3.3-70b-versatile",
    glossary: dict = None
) -> str:
    """
    é˜¶æ®µä¸€ï¼šå…¨æ–‡ç†è§£ç¿»è¯‘
    å°†æ‰€æœ‰å­—å¹•æ‹¼æˆå®Œæ•´æ–‡ç« ï¼Œä¸€æ¬¡æ€§ç¿»è¯‘ï¼Œç¡®ä¿ä¸Šä¸‹æ–‡è¿è´¯
    """
    # æ„å»ºå¸¦ç¼–å·çš„å®Œæ•´åŸæ–‡
    full_text_lines = []
    for i, sub in enumerate(subtitles):
        full_text_lines.append(sub['text'])
    full_text = " ".join(full_text_lines)

    glossary_prompt = build_glossary_prompt(glossary or {})

    system_prompt = f"ä½ æ˜¯ä¸“ä¸šçš„è§†é¢‘å­—å¹•ç¿»è¯‘å‘˜ã€‚è¯·å°†å®Œæ•´çš„è§†é¢‘å†…å®¹ç¿»è¯‘ä¸ºè‡ªç„¶æµç•…çš„{target_lang}ã€‚"

    user_prompt = f"""ä»¥ä¸‹æ˜¯ä¸€æ®µå®Œæ•´çš„è§†é¢‘å†…å®¹ï¼ˆ{source_lang}ï¼‰ã€‚è¯·å…ˆé€šè¯»ç†è§£å…¨éƒ¨å†…å®¹ï¼Œç„¶åä½œä¸ºä¸€ç¯‡å®Œæ•´çš„æ–‡ç« ç¿»è¯‘ä¸º{target_lang}ã€‚

ç¿»è¯‘è¦æ±‚ï¼š
1. å…ˆç†è§£æ•´ä½“å†…å®¹å’Œè¯­å¢ƒï¼Œå†ç¿»è¯‘
2. å£è¯­åŒ–ã€ç®€æ´æµç•…ï¼Œé€‚åˆè§†é¢‘å­—å¹•
3. ä¿æŒåŸæ–‡çš„è¯­æ°”å’Œé£æ ¼ï¼ˆå¦‚è®½åˆºã€å¹½é»˜ã€æ­£å¼ç­‰ï¼‰
4. åªè¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦ä»»ä½•è§£é‡Š{glossary_prompt}

å®Œæ•´å†…å®¹ï¼š
{full_text}"""

    return call_llm(client, system_prompt, user_prompt, model)


def phase2_distribute(
    client: Groq,
    holistic_translation: str,
    subtitles: List[Dict],
    target_lang: str = "ä¸­æ–‡",
    model: str = "llama-3.3-70b-versatile",
    glossary: dict = None
) -> List[str]:
    """
    é˜¶æ®µäºŒï¼šæ—¶é—´ç åˆ†é…
    æ ¹æ®å®Œæ•´ç¿»è¯‘å’Œæ¯æ®µæ—¶é—´ç çš„æ—¶é•¿ï¼Œåˆ†é…ç¿»è¯‘å†…å®¹
    çŸ­æ—¶é—´ç å‹ç¼©ï¼Œé•¿æ—¶é—´ç æ‰©å……
    """
    # æ„å»ºæ®µè½ä¿¡æ¯ï¼ˆå«æ—¶é•¿å’ŒåŸæ–‡ï¼‰
    segments_info_lines = []
    for i, sub in enumerate(subtitles):
        duration = sub['end'] - sub['start']
        # ä¼°ç®—ç›®æ ‡å­—æ•°ï¼šä¸­æ–‡è¯­é€Ÿçº¦ 3-4 å­—/ç§’
        target_chars = max(2, int(duration * 3.5))
        segments_info_lines.append(
            f"[{i}] æ—¶é•¿{duration:.1f}ç§’ (ç›®æ ‡çº¦{target_chars}å­—) | åŸæ–‡: {sub['text']}"
        )
    segments_info = "\n".join(segments_info_lines)

    glossary_prompt = build_glossary_prompt(glossary or {})

    system_prompt = "ä½ æ˜¯ä¸“ä¸šçš„è§†é¢‘å­—å¹•ç¿»è¯‘å‘˜ã€‚æ ¹æ®å®Œæ•´ç¿»è¯‘å’Œæ—¶é—´ç ä¿¡æ¯ï¼Œå°†ç¿»è¯‘å†…å®¹åˆ†é…åˆ°å„æ®µã€‚ä¸¥æ ¼æŒ‰ \"åºå·: ç¿»è¯‘\" æ ¼å¼è¾“å‡ºã€‚"

    user_prompt = f"""å·²æœ‰ä¸€æ®µè§†é¢‘çš„å®Œæ•´{target_lang}ç¿»è¯‘ï¼Œç°åœ¨éœ€è¦æŠŠç¿»è¯‘å†…å®¹åˆ†é…åˆ°å„ä¸ªæ—¶é—´ç æ®µè½ä¸­ã€‚

å®Œæ•´ç¿»è¯‘ï¼ˆå‚è€ƒï¼‰ï¼š
{holistic_translation}

å„æ®µè½çš„æ—¶é—´ç ä¿¡æ¯ï¼š
{segments_info}

æ ¸å¿ƒåŸåˆ™ï¼šé»˜è®¤å®Œæ•´ç¿»è¯‘åŸæ–‡çš„æ¯ä¸€ä¸ªæ„æ€ï¼Œä¸è¦çœç•¥ï¼åªæœ‰æ—¶é•¿æçŸ­ï¼ˆ<1.5ç§’ï¼‰çš„æ®µè½æ‰å¯ä»¥é€‚å½“ç²¾ç®€ã€‚

åˆ†é…è§„åˆ™ï¼š
1. æ¯æ®µçš„ã€Œç›®æ ‡çº¦Nå­—ã€æ˜¯å‚è€ƒå€¼ï¼Œç¿»è¯‘åº”å°½é‡æ¥è¿‘è¿™ä¸ªå­—æ•°ï¼Œä¸è¦è¿œå°‘äºå®ƒ
2. æ—¶é•¿â‰¥2ç§’çš„æ®µè½ï¼šå¿…é¡»å®Œæ•´ç¿»è¯‘åŸæ–‡çš„å…¨éƒ¨æ„æ€ï¼Œä¸èƒ½çœç•¥ä»»ä½•ä¿¡æ¯
   - ä¾‹å¦‚åŸæ–‡ "Improved communication with your mom can bring you closer"
   - æ­£ç¡®: "æ”¹å–„ä¸å¦ˆå¦ˆçš„æ²Ÿé€šå¯ä»¥æ‹‰è¿‘ä½ ä»¬çš„è·ç¦»"ï¼ˆå®Œæ•´æ„æ€ï¼‰
   - é”™è¯¯: "æ”¹å–„ä¸å¦ˆå¦ˆçš„æ²Ÿé€š"ï¼ˆçœç•¥äº†"å¯ä»¥æ‹‰è¿‘è·ç¦»"ï¼‰
3. æ—¶é•¿<1.5ç§’çš„æ®µè½ï¼šå¯ä»¥åªä¿ç•™æ ¸å¿ƒè¯ï¼Œå¦‚ "å¥½é—®é¢˜" "ä»€ä¹ˆï¼Ÿ"
4. æ—¶é•¿>8ç§’çš„æ®µè½ï¼šåº”è¯¥ç¿»è¯‘å¾—å……åˆ†è¯¦ç»†ï¼ŒæŠŠå®Œæ•´ç¿»è¯‘ä¸­å¯¹åº”çš„å†…å®¹éƒ½åˆ†é…è¿›å»
5. ç¡®ä¿å®Œæ•´ç¿»è¯‘çš„æ‰€æœ‰ä¿¡æ¯éƒ½è¢«åˆ†é…åˆ°å„æ®µä¸­ï¼Œä¸é—æ¼ä»»ä½•å†…å®¹{glossary_prompt}

è¯·ä¸¥æ ¼æŒ‰ "åºå·: ç¿»è¯‘" æ ¼å¼è¾“å‡ºï¼Œæ¯è¡Œä¸€æ¡ï¼Œä¸è¦ä»»ä½•å…¶ä»–å†…å®¹ï¼š"""

    result_text = call_llm(client, system_prompt, user_prompt, model)

    # è§£æå“åº”
    translations = {}
    for line in result_text.split("\n"):
        line = line.strip()
        if not line:
            continue
        match = re.match(r'^\[?(\d+)\]?\s*[:ï¼š.]\s*(.+)$', line)
        if match:
            idx = int(match.group(1))
            text = match.group(2).strip()
            translations[idx] = text

    # æŒ‰åºå·æ„å»ºç»“æœ
    result = []
    for i in range(len(subtitles)):
        if i in translations:
            result.append(translations[i])
        else:
            result.append(f"[ç¿»è¯‘å¤±è´¥: {subtitles[i]['text'][:20]}...]")

    return result


def phase2_distribute_batched(
    client: Groq,
    holistic_translation: str,
    subtitles: List[Dict],
    batch_size: int = 50,
    target_lang: str = "ä¸­æ–‡",
    model: str = "llama-3.3-70b-versatile",
    glossary: dict = None
) -> List[str]:
    """
    é˜¶æ®µäºŒï¼ˆåˆ†æ‰¹ç‰ˆï¼‰ï¼šå¯¹é•¿è§†é¢‘åˆ†æ‰¹åˆ†é…ç¿»è¯‘
    æ¯æ‰¹æä¾›å®Œæ•´ç¿»è¯‘ä½œä¸ºä¸Šä¸‹æ–‡å‚è€ƒ
    """
    total = len(subtitles)
    if total <= batch_size:
        return phase2_distribute(client, holistic_translation, subtitles,
                                 target_lang, model, glossary)

    num_batches = (total + batch_size - 1) // batch_size
    all_translations = []

    for batch_idx in range(num_batches):
        start_i = batch_idx * batch_size
        end_i = min(start_i + batch_size, total)
        batch = subtitles[start_i:end_i]

        print(f"   ğŸ“ åˆ†é…ç¬¬ {start_i + 1}-{end_i} æ¡...", end=" ", flush=True)

        translations = phase2_distribute(
            client, holistic_translation, batch,
            target_lang, model, glossary
        )

        # ä¿®æ­£åºå·ï¼ˆå› ä¸º batch å†…çš„åºå·ä» 0 å¼€å§‹ï¼Œä½†å®é™…æ˜¯ä» start_i å¼€å§‹ï¼‰
        all_translations.extend(translations)
        print("âœ…")

        if batch_idx < num_batches - 1:
            time.sleep(0.5)

    return all_translations


def clean_punctuation(text: str) -> str:
    """
    æ¸…ç†ä¸­æ–‡å­—å¹•æ ‡ç‚¹ï¼š
    1. åˆ é™¤æ¯è¡Œæœ«å°¾çš„å¥å·ï¼ˆã€‚ï¼‰å’Œé€—å·ï¼ˆï¼Œï¼‰
    2. å°†ä¸­é—´çš„é€—å·ï¼ˆï¼Œï¼‰å’Œé¡¿å·ï¼ˆã€ï¼‰æ›¿æ¢ä¸ºç©ºæ ¼
    """
    lines = text.replace("\\N", "\n").split("\n")
    result = []
    for line in lines:
        line = line.strip()
        if not line:
            continue
        line = line.rstrip("ã€‚ï¼Œ")
        line = line.replace("ï¼Œ", " ").replace("ã€", " ")
        result.append(line)
    return "\n".join(result)


def enforce_line_length(text: str, max_chars: int = 25) -> str:
    """å°† \\N å’Œæ¢è¡Œåˆå¹¶ä¸ºå•è¡Œ"""
    text = text.replace("\\N", " ").replace("\n", " ")
    text = re.sub(r'\s+', ' ', text).strip()
    return text


def split_long_subtitles(translated: List[Dict], max_chars: int = 25,
                         content_key: str = "translation") -> List[Dict]:
    """æ‹†åˆ†è¿‡é•¿çš„ä¸­æ–‡å­—å¹•ä¸ºä¸¤æ¡"""
    result = []
    split_count = 0

    for sub in translated:
        text = sub.get(content_key, '')
        if len(text) <= max_chars:
            result.append(sub)
            continue

        mid = len(text) // 2
        best_pos = -1
        for offset in range(len(text)):
            right = mid + offset
            left = mid - offset
            if right < len(text) and text[right] == ' ':
                best_pos = right
                break
            if left >= 0 and text[left] == ' ':
                best_pos = left
                break

        if best_pos <= 0 or best_pos >= len(text) - 1:
            result.append(sub)
            continue

        first_text = text[:best_pos].strip()
        second_text = text[best_pos:].strip()

        if not first_text or not second_text:
            result.append(sub)
            continue

        start = sub['start']
        end = sub['end']
        duration = end - start
        ratio = len(first_text) / (len(first_text) + len(second_text))
        split_time = round(start + duration * ratio, 3)

        first_sub = dict(sub)
        first_sub['end'] = split_time
        first_sub[content_key] = first_text

        second_sub = dict(sub)
        second_sub['start'] = split_time
        second_sub['text'] = ''
        second_sub[content_key] = second_text

        result.append(first_sub)
        result.append(second_sub)
        split_count += 1

    if split_count > 0:
        print(f"   âœ‚ï¸ æ‹†åˆ† {split_count} æ¡è¿‡é•¿å­—å¹• (>{max_chars}å­—)")

    return result


def translate_subtitles(
    subtitles: List[Dict],
    batch_size: int = 50,
    target_lang: str = "ä¸­æ–‡",
    source_lang: str = "è‹±æ–‡",
    model: str = "llama-3.3-70b-versatile",
    glossary: dict = None,
    max_retries: int = 3
) -> List[Dict]:
    """
    ä¸¤é˜¶æ®µç¿»è¯‘æ³•ï¼š
    Phase 1: å…¨æ–‡ç†è§£ç¿»è¯‘ - é€šè¯»å…¨éƒ¨å†…å®¹åæ•´ä½“ç¿»è¯‘
    Phase 2: æ—¶é—´ç åˆ†é… - æ ¹æ®æ—¶é•¿å‹ç¼©/æ‰©å……åˆ†é…åˆ°å„æ®µ
    """
    api_key = os.environ.get('GROQ_API_KEY', '').strip()
    if not api_key:
        raise ValueError(
            "âŒ æœªè®¾ç½® GROQ_API_KEY æˆ–å€¼ä¸ºç©º\n"
            "   1. ç”³è¯· Key: https://console.groq.com/keys\n"
            "   2. è®¾ç½®: export GROQ_API_KEY='gsk_...'"
        )
    if not api_key.startswith('gsk_'):
        raise ValueError(
            "âŒ GROQ_API_KEY æ ¼å¼ä¸æ­£ç¡®ï¼ˆåº”ä»¥ 'gsk_' å¼€å¤´ï¼‰\n"
            "   è¯·æ£€æŸ¥æ˜¯å¦å¤åˆ¶äº†å®Œæ•´çš„ Key: https://console.groq.com/keys"
        )

    client = Groq(api_key=api_key)

    subtitles = [s for s in subtitles if s.get('text', '').strip()]
    total = len(subtitles)

    print(f"\nğŸŒ ä¸¤é˜¶æ®µç¿»è¯‘æ³• (Groq LLM: {model})")
    print(f"   æ€»æ¡æ•°: {total}")
    print(f"   æºè¯­è¨€: {source_lang} â†’ ç›®æ ‡è¯­è¨€: {target_lang}")
    if glossary:
        print(f"   è¯è¡¨: {len(glossary)} æ¡")

    # ===== Phase 1: å…¨æ–‡ç†è§£ç¿»è¯‘ =====
    print(f"\n   ğŸ“– é˜¶æ®µä¸€ï¼šå…¨æ–‡ç†è§£ç¿»è¯‘...", end=" ", flush=True)
    try:
        holistic_translation = phase1_holistic_translate(
            client, subtitles, target_lang, source_lang, model, glossary
        )
        print("âœ…")
        print(f"   å®Œæ•´ç¿»è¯‘ ({len(holistic_translation)} å­—):")
        # æ˜¾ç¤ºç¿»è¯‘é¢„è§ˆï¼ˆå‰200å­—ï¼‰
        preview = holistic_translation[:200]
        if len(holistic_translation) > 200:
            preview += "..."
        print(f"   ã€Œ{preview}ã€")
    except Exception as e:
        from utils import sanitize_error_message
        print(f"âŒ å¤±è´¥: {sanitize_error_message(str(e))}")
        raise

    # ===== Phase 2: æ—¶é—´ç åˆ†é… =====
    print(f"\n   ğŸ“ é˜¶æ®µäºŒï¼šæŒ‰æ—¶é—´ç åˆ†é…ç¿»è¯‘...", end=" ", flush=True)
    try:
        translations = phase2_distribute_batched(
            client, holistic_translation, subtitles,
            batch_size, target_lang, model, glossary
        )
        print("âœ…")
    except Exception as e:
        from utils import sanitize_error_message
        print(f"âŒ å¤±è´¥: {sanitize_error_message(str(e))}")
        raise

    # ===== åå¤„ç† =====
    translated = []
    for i, sub in enumerate(subtitles):
        trans_text = translations[i] if i < len(translations) else "[ç¿»è¯‘å¤±è´¥]"
        trans_text = clean_punctuation(trans_text)
        trans_text = enforce_line_length(trans_text, 25)
        translated.append({
            'start': sub['start'],
            'end': sub['end'],
            'text': sub['text'],
            'translation': trans_text
        })

    print(f"\n   âœ… ç¿»è¯‘å®Œæˆ: {total}/{total} æ¡")

    return translated


def save_translated_srt(
    translated: List[Dict],
    output_path: str,
    content_key: str = "translation"
):
    """ä¿å­˜ç¿»è¯‘åçš„å­—å¹•ä¸º SRT æ–‡ä»¶"""
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        for i, sub in enumerate(translated, 1):
            f.write(f"{i}\n")
            start_time = seconds_to_time(sub['start'], include_hours=True, use_comma=True)
            end_time = seconds_to_time(sub['end'], include_hours=True, use_comma=True)
            f.write(f"{start_time} --> {end_time}\n")
            text = sub[content_key]
            f.write(f"{text}\n")
            f.write("\n")

    print(f"ğŸ’¾ å·²ä¿å­˜: {output_path}")


def save_bilingual_srt(translated: List[Dict], output_path: str):
    """ä¿å­˜åŒè¯­å­—å¹•ï¼ˆè‹±æ–‡åœ¨ä¸Šï¼Œä¸­æ–‡åœ¨ä¸‹ï¼‰"""
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        for i, sub in enumerate(translated, 1):
            f.write(f"{i}\n")
            start_time = seconds_to_time(sub['start'], include_hours=True, use_comma=True)
            end_time = seconds_to_time(sub['end'], include_hours=True, use_comma=True)
            f.write(f"{start_time} --> {end_time}\n")
            f.write(f"{sub['text']}\n{sub['translation']}\n")
            f.write("\n")

    print(f"ğŸ’¾ åŒè¯­å­—å¹•å·²ä¿å­˜: {output_path}")


def load_subtitles_from_srt(srt_path: str) -> List[Dict]:
    """ä» SRT æ–‡ä»¶åŠ è½½å­—å¹•"""
    try:
        import pysrt
    except ImportError:
        print("âŒ Error: pysrt not installed")
        print("Please install: pip install pysrt")
        sys.exit(1)

    srt_path = Path(srt_path)
    if not srt_path.exists():
        raise FileNotFoundError(f"SRT file not found: {srt_path}")

    print(f"ğŸ“‚ åŠ è½½ SRT å­—å¹•: {srt_path.name}")

    subs = pysrt.open(srt_path)
    subtitles = []

    skipped = 0
    for sub in subs:
        text = sub.text.replace('\n', ' ').strip()
        if not text:
            skipped += 1
            continue
        start = sub.start.hours * 3600 + sub.start.minutes * 60 + sub.start.seconds + sub.start.milliseconds / 1000
        end = sub.end.hours * 3600 + sub.end.minutes * 60 + sub.end.seconds + sub.end.milliseconds / 1000
        subtitles.append({
            'start': start,
            'end': end,
            'text': text
        })

    print(f"   æ‰¾åˆ° {len(subtitles)} æ¡å­—å¹•")
    if skipped > 0:
        print(f"   âš ï¸  å·²è¿‡æ»¤ {skipped} æ¡ç©ºå­—å¹•")
    return subtitles


LANG_CODE_MAP = {
    'en': 'è‹±æ–‡', 'english': 'è‹±æ–‡',
    'zh': 'ä¸­æ–‡', 'chinese': 'ä¸­æ–‡',
    'ja': 'æ—¥æ–‡', 'japanese': 'æ—¥æ–‡',
    'ko': 'éŸ©æ–‡', 'korean': 'éŸ©æ–‡',
    'fr': 'æ³•æ–‡', 'french': 'æ³•æ–‡',
    'de': 'å¾·æ–‡', 'german': 'å¾·æ–‡',
    'es': 'è¥¿ç­ç‰™æ–‡', 'spanish': 'è¥¿ç­ç‰™æ–‡',
    'pt': 'è‘¡è„ç‰™æ–‡', 'portuguese': 'è‘¡è„ç‰™æ–‡',
    'ru': 'ä¿„æ–‡', 'russian': 'ä¿„æ–‡',
    'ar': 'é˜¿æ‹‰ä¼¯æ–‡', 'arabic': 'é˜¿æ‹‰ä¼¯æ–‡',
    'it': 'æ„å¤§åˆ©æ–‡', 'italian': 'æ„å¤§åˆ©æ–‡',
    'th': 'æ³°æ–‡', 'thai': 'æ³°æ–‡',
    'vi': 'è¶Šå—æ–‡', 'vietnamese': 'è¶Šå—æ–‡',
    'hi': 'å°åœ°æ–‡', 'hindi': 'å°åœ°æ–‡',
    'tr': 'åœŸè€³å…¶æ–‡', 'turkish': 'åœŸè€³å…¶æ–‡',
    'fa': 'æ³¢æ–¯æ–‡', 'persian': 'æ³¢æ–¯æ–‡',
    'he': 'å¸Œä¼¯æ¥æ–‡', 'hebrew': 'å¸Œä¼¯æ¥æ–‡',
    'uk': 'ä¹Œå…‹å…°æ–‡', 'ukrainian': 'ä¹Œå…‹å…°æ–‡',
    'pl': 'æ³¢å…°æ–‡', 'polish': 'æ³¢å…°æ–‡',
    'nl': 'è·å…°æ–‡', 'dutch': 'è·å…°æ–‡',
    'sv': 'ç‘å…¸æ–‡', 'swedish': 'ç‘å…¸æ–‡',
}


def lang_code_to_name(code: str) -> str:
    """å°† Whisper è¯­è¨€ä»£ç è½¬æ¢ä¸ºä¸­æ–‡è¯­è¨€åç§°"""
    return LANG_CODE_MAP.get(code.lower(), code)


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    if len(sys.argv) < 2:
        print("Usage: python translate_subtitles.py <srt_file> [chinese_output] [bilingual_output] [batch_size] [--source-lang CODE]")
        print("\nArguments:")
        print("  srt_file          - è¾“å…¥ SRT å­—å¹•æ–‡ä»¶")
        print("  chinese_output    - ä¸­æ–‡å­—å¹•è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰")
        print("  bilingual_output  - åŒè¯­å­—å¹•è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰")
        print("  batch_size        - é˜¶æ®µäºŒæ¯æ‰¹åˆ†é…æ•°é‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤ 50ï¼‰")
        print("\nOptions:")
        print("  --source-lang CODE  - æºè¯­è¨€ä»£ç ï¼ˆå¦‚ en, ja, ko, frï¼‰ï¼Œé»˜è®¤ en")
        print("\nExample:")
        print("  python translate_subtitles.py video_original.srt")
        print("  python translate_subtitles.py video_original.srt video_chinese.srt")
        print("  python translate_subtitles.py video_original.srt video_chinese.srt --source-lang ja")
        print("\nRequires: GROQ_API_KEY environment variable")
        sys.exit(1)

    # è§£æ --source-lang å‚æ•°
    source_lang_code = "en"
    args = list(sys.argv[1:])
    if "--source-lang" in args:
        idx = args.index("--source-lang")
        if idx + 1 < len(args):
            source_lang_code = args[idx + 1]
            args = args[:idx] + args[idx + 2:]
        else:
            args = args[:idx]

    source_lang = lang_code_to_name(source_lang_code)

    srt_file = args[0]
    srt_path = Path(srt_file)

    chinese_output = args[1] if len(args) > 1 else str(
        srt_path.parent / f"{srt_path.stem.replace('_original', '')}_chinese.srt"
    )
    bilingual_output = args[2] if len(args) > 2 else None
    batch_size = int(args[3]) if len(args) > 3 else 50

    glossary_path = srt_path.parent / "glossary.json"
    glossary = load_glossary(str(glossary_path) if glossary_path.exists() else None)

    try:
        subtitles = load_subtitles_from_srt(srt_file)

        if not subtitles:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆå­—å¹•")
            sys.exit(1)

        translated = translate_subtitles(subtitles, batch_size,
                                         source_lang=source_lang,
                                         glossary=glossary)

        save_translated_srt(translated, chinese_output)

        if bilingual_output:
            save_bilingual_srt(translated, bilingual_output)

        print(f"\nâœ¨ ç¿»è¯‘å®Œæˆï¼")
        print(f"   ä¸­æ–‡å­—å¹•: {chinese_output}")
        if bilingual_output:
            print(f"   åŒè¯­å­—å¹•: {bilingual_output}")

    except Exception as e:
        from utils import sanitize_error_message
        print(f"\nâŒ é”™è¯¯: {sanitize_error_message(str(e))}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
